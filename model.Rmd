---
title: "Model"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load("ggplot2","tidyverse","rstanarm","dplyr","pwr","MASS","arm","lme4","tidyr")
```

```{r}
library(dplyr)
eng<-read.csv("eng.csv")
#eng
spa<-read.csv("spa.csv")
#spa
```

```{r}
#44 items labeled as cognate/noncognate.
eng1<-eng%>%filter(!word %in% c('bed','tree', 'pencil', 'house', 'whistle','scissors','saw','toothbrush','pretzel','bench','globe','cactus','escalator','pelican',
                              'stethoscope','palette'))
#eng1

```

```{r}
#code： cognate=1, noncognate=0.
eng1$cognate[eng1$word %in% c('comb','broom','octopus','mushroom','hanger','wheelchair','snail','seahorse','wreath',
'beaver','stilts','acorn','knocker','muzzle','funnel','noose','latch','scroll','tongs','yoke','trellis','protractor')] <- 0
eng1$cognate[!eng1$word %in% c('comb','broom','octopus','mushroom','hanger','wheelchair','snail','seahorse','wreath',
'beaver','stilts','acorn','knocker','muzzle','funnel','noose','latch','scroll','tongs','yoke','trellis','protractor')] <- 1
eng1
#write.csv(eng1,"eng1.csv",row.names=FALSE)
```

```{r}
#44 items labeled as cognate/noncognate.
spa1<-spa%>%filter(!word %in% c('bed','tree', 'pencil', 'house', 'whistle','scissors','saw','toothbrush','pretzel','bench','globe','cactus','escalator','pelican',
                              'stethoscope','palette'))
#spa1
```

```{r}
#code： cognate=1, noncognate=0.
spa1$cognate[spa1$word %in% c('comb','broom','octopus','mushroom','hanger','wheelchair','snail','seahorse','wreath',
'beaver','stilts','acorn','knocker','muzzle','funnel','noose','latch','scroll','tongs','yoke','trellis','protractor')] <- 0
spa1$cognate[!spa1$word %in% c('comb','broom','octopus','mushroom','hanger','wheelchair','snail','seahorse','wreath',
'beaver','stilts','acorn','knocker','muzzle','funnel','noose','latch','scroll','tongs','yoke','trellis','protractor')] <- 1
spa1
#write.csv(spa1,"spa1.csv",row.names=FALSE)
```

```{r}
#logistic regression model for english data:
M1<-glm(accuracy~cognate, family=binomial(link="logit"),data=eng1)
summary(M1)
```

invlogit(-0.56+0.33*1)=0.44
invlogit(-0.56)=0.36


```{r}
#logistic regression model for spanish data:
M2<-glm(accuracy~cognate, family=binomial(link="logit"),data=spa1)
summary(M2)
```

invlogit(-1.23+0.69*1)=0.37
invlogit(-1.23)=0.23


## Add random variable into logistic model 
```{r}
M3 <- glmer(accuracy~1+(1|cognate),data=eng1,family=binomial(link="logit"))
print(M3)
```

```{r}
M4 <- glmer(accuracy~1+(1|cognate),data=spa1,family=binomial(link="logit"))
print(M4)
```

##add difficulty into the dataset
```{r}
spa2 <- read.csv("spa2.csv",header = T)
eng2 <- read.csv("eng2.csv",header = T)
eng2$diff <- as.numeric(eng2$diff)
spa2$diff <- as.numeric(spa2$diff)
```

## refit the model 
```{r}
M5 <- glmer(accuracy~cognate+(1|subject)+diff,data=eng2,family=binomial(link="logit"))
print(summary(M5))

library(boot)
inv.logit(2.1693)
inv.logit(0.7015)
inv.logit(-0.8832)

lattice::dotplot(ranef(M5,which="subject",condVar=TRUE))
```

Interpret:
Intercept: For non-cognate words with same difficulty level, the possibility of answer the words accurately is 89.76%.
Cognate: Words with same difficulty level, cognate worlds tend to have 66.85% higher possibility to be correctly answered.
diff: For non-Cognates word, it has 29.25% higher possibility to be correctly answered as the difficulty increasing. 

```{r}
M6 <- glmer(accuracy~cognate+(1|subject)+diff,data=spa2,family=binomial(link="logit"))
print(summary(M6))
inv.logit(1.055)
inv.logit(1.1634)
inv.logit(-0.8374)

lattice::dotplot(ranef(M6,which="subject",condVar=TRUE))
```

Interpret:
Intercept: For non-cognate words with same difficulty level, the possibility of answer the words accurately is 74.17%.
Cognate: Words with same difficulty level, cognate worlds tend to have 76.195% higher possibility to be correctly answered.
diff: For non-Cognates word, it has 30.2% higher possibility to be correctly answered as the difficulty increasing. 


## Mixed effect logistic regression
```{r}
comb <- read.csv("comb.csv",header=T)
comb <- unite(comb,"accuracy",c("eng.acc","spa.acc"),sep="",remove = F)
comb<- comb[-115,]
comb$category <- rep(NA,1143)
for (i in 1:1143){
  if (comb$eng.acc[i] == 0 && comb$spa.acc[i] == 0) {
    comb$category[i] <- 1 
  }
  if (comb$eng.acc[i] == 0 && comb$spa.acc[i] == 1) {
    comb$category[i] <- 2 
  }
  if (comb$eng.acc[i] == 1 && comb$spa.acc[i] == 0) {
    comb$category[i] <- 3 
  }
  if (comb$eng.acc[i] == 1 && comb$spa.acc[i] == 1) {
    comb$category[i] <- 4
  }
}
```

```{r}
#multinomial model
M7 <- polr(factor(category)~cognate+diff,data=comb)
print(summary(M7))
```

Interpretation: 
for $$z=0.5524*cognate-0.5502*diff$$, 
$$
\left\{  
             \begin{array}{**lr**}  
             category=1, &if \quad z<-1.9780\\  
             category=2, & if \quad -1.9780<z<-1.4136\\  
             category=3, & if \quad -1.4136<z<-0.1001\\
             category=4, & if \quad z>-0.1001
             \end{array}  
\right.
$$


